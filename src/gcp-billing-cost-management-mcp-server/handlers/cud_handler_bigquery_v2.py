"""
CUD Commitments List - BigQuery Implementation (Corrected)

Based on actual data analysis, CUD commitments are identified by:
- SKU description pattern: "Commitment v1:"
- cost_type is 'regular' (NOT 'commitment')
- CUD usage credits have credits.type = 'COMMITTED_USAGE_DISCOUNT'
"""

import logging
from datetime import datetime, timedelta
from typing import Any

logger = logging.getLogger(__name__)
from mcp.server.fastmcp import Context


from utils.multi_account_client import (
    get_bigquery_client_for_account,
)
from services.gcp_credentials_provider import get_gcp_credentials_provider


async def list_commitments_from_bigquery(
    ctx: Context,
    project_id: str | None = None,
    billing_account_id: str | None = None,
    region: str | None = None,
    account_id: str | None = None,
    days_lookback: int = 30,
) -> dict[str, Any]:
    """List CUD commitments from BigQuery billing export (CORRECTED VERSION)

    This function analyzes billing data to identify CUD commitments using
    the CORRECT data patterns found in actual GCP billing exports.

    Key findings from data analysis:
    - CUD fees have SKU description starting with "Commitment v1:"
    - All records have cost_type = 'regular' (not 'commitment')
    - CUD usage is tracked via credits with type = 'COMMITTED_USAGE_DISCOUNT'

    Args:
        ctx: MCP context
        project_id: GCP project ID (optional, for single project)
        billing_account_id: Billing account ID (recommended for org-level)
        region: Filter by specific region
        account_id: GCP account ID for credentials
        days_lookback: Number of days to analyze (default: 30)

    Returns:
        Dictionary with commitment information extracted from billing data
    """
    operation = "list_commitments_from_bigquery"

    # Smart default
    if not project_id and not billing_account_id:
        credentials_provider = get_gcp_credentials_provider()
        account_info = credentials_provider.get_account_info(account_id or "default")
        if account_info and account_info.get("billing_account_id"):
            billing_account_id = account_info["billing_account_id"]
            logger.info(f"ğŸ¯ ä½¿ç”¨è´¦å·é…ç½®çš„ billing_account_id: {billing_account_id}")
        elif account_info:
            project_id = account_info["project_id"]
            logger.info(f"ğŸ¯ ä½¿ç”¨è´¦å·é…ç½®çš„ project_id: {project_id}")

    logger.info(f"ğŸ” {operation} - ä» BigQuery æŸ¥è¯¢ CUD æ‰¿è¯ºæ•°æ®ï¼ˆä¿®æ­£ç‰ˆï¼‰")

    try:
        # Get BigQuery client and table name
        provider = get_gcp_credentials_provider()
        table_name = provider.get_bigquery_table_name(account_id or "default")

        if not table_name:
            return {
                "success": False,
                "error_message": "BigQuery billing export not configured",
                "data": None,
            }

        bq_client = get_bigquery_client_for_account(account_id)

        # Calculate date range
        end_date = datetime.now() - timedelta(days=2)
        start_date = end_date - timedelta(days=days_lookback)
        start_date_str = start_date.strftime("%Y-%m-%d")
        end_date_str = end_date.strftime("%Y-%m-%d")

        # Build scope filter
        if billing_account_id:
            scope_filter = f"AND billing_account_id = '{billing_account_id}'"
            logger.info(f"ğŸ“Š æŸ¥è¯¢èŒƒå›´: Billing Account {billing_account_id}")
        else:
            scope_filter = f"AND project.id = '{project_id}'"
            logger.info(f"ğŸ“Š æŸ¥è¯¢èŒƒå›´: Project {project_id}")

        # Build region filter
        region_filter = f"AND location.region = '{region}'" if region else ""

        # âœ… PERFECT SOLUTION - Correct CUD utilization calculation
        # Based on industry best practices and GCP official documentation
        query = f"""
        WITH commitment_fees AS (
          -- Step 1: Extract CUD commitment fees (discounted price)
          -- Key: SKU description starts with "Commitment v1:"
          SELECT
            project.id AS project_id,
            project.name AS project_name,
            location.region AS region,
            sku.description AS sku_description,
            SUM(cost) AS commitment_cost_discounted,
            -- Extract discount rate from commitment term
            -- 1-Year: 28% discount, 3-Year: 46% discount
            CASE
              WHEN sku.description LIKE '%1 Year%' THEN 0.28
              WHEN sku.description LIKE '%3 Year%' THEN 0.46
              ELSE 0.37  -- Default average
            END AS discount_rate,
            currency,
            MIN(_PARTITIONDATE) AS first_seen,
            MAX(_PARTITIONDATE) AS last_seen,
            COUNT(DISTINCT _PARTITIONDATE) AS days_active,
            -- Parse commitment type from SKU
            CASE
              WHEN LOWER(sku.description) LIKE '%cpu%' THEN 'CPU'
              WHEN LOWER(sku.description) LIKE '%ram%' OR LOWER(sku.description) LIKE '%memory%' THEN 'RAM'
              WHEN LOWER(sku.description) LIKE '%gpu%' THEN 'GPU'
              WHEN LOWER(sku.description) LIKE '%ssd%' THEN 'Local SSD'
              ELSE 'Other'
            END AS resource_type,
            -- Parse commitment term from SKU
            CASE
              WHEN sku.description LIKE '%1 Year%' THEN '1-Year'
              WHEN sku.description LIKE '%3 Year%' THEN '3-Year'
              ELSE 'Unknown'
            END AS commitment_term
          FROM `{table_name}`
          WHERE _PARTITIONDATE BETWEEN '{start_date_str}' AND '{end_date_str}'
            AND service.description = 'Compute Engine'
            AND sku.description LIKE 'Commitment v1:%'
            {scope_filter}
            {region_filter}
          GROUP BY project_id, project_name, region, sku_description, currency
          HAVING SUM(cost) > 0
        ),
        cud_covered_usage AS (
          -- Step 2: Extract usage covered by CUD (at on-demand price)
          -- Method 1: Try to get COMMITTED_USAGE_DISCOUNT_COVERAGE (most accurate)
          -- Method 2: Fallback to COMMITTED_USAGE_DISCOUNT credits (discount amount)
          SELECT
            project.id AS project_id,
            location.region AS region,
            -- Sum the on-demand cost of resources that received CUD discount
            SUM(cost) AS usage_cost_on_demand,
            -- Also get the credit amount for reference
            ABS(SUM(
              (SELECT SUM(c.amount)
               FROM UNNEST(credits) AS c
               WHERE c.type = 'COMMITTED_USAGE_DISCOUNT')
            )) AS cud_credits_discount
          FROM `{table_name}`
          WHERE _PARTITIONDATE BETWEEN '{start_date_str}' AND '{end_date_str}'
            AND service.description = 'Compute Engine'
            AND EXISTS(SELECT 1 FROM UNNEST(credits) AS c
                       WHERE c.type = 'COMMITTED_USAGE_DISCOUNT')
            {scope_filter}
            {region_filter}
          GROUP BY project_id, region
        ),
        combined_data AS (
          -- Step 3: Combine and calculate on-demand equivalent value
          SELECT
            f.project_id,
            f.project_name,
            f.region,
            f.sku_description,
            f.resource_type,
            f.commitment_term,
            f.commitment_cost_discounted,
            f.discount_rate,
            -- Calculate commitment's on-demand equivalent value
            -- Formula: discounted_cost / (1 - discount_rate)
            -- Example: $1000 discounted at 46% = $1000 / 0.54 = $1852 on-demand value
            ROUND(f.commitment_cost_discounted / (1 - f.discount_rate), 2) AS commitment_on_demand_value,
            COALESCE(u.usage_cost_on_demand, 0) AS usage_cost_on_demand,
            COALESCE(u.cud_credits_discount, 0) AS cud_credits_discount,
            f.currency,
            f.first_seen,
            f.last_seen,
            f.days_active
          FROM commitment_fees f
          LEFT JOIN cud_covered_usage u
            ON f.project_id = u.project_id
            AND (f.region = u.region OR (f.region IS NULL AND u.region IS NULL))
        )
        -- Step 4: Calculate correct utilization
        SELECT
          project_id,
          project_name,
          region,
          sku_description,
          resource_type,
          commitment_term,
          -- Commitment cost (what you actually pay - discounted)
          ROUND(commitment_cost_discounted, 2) AS commitment_cost,
          -- Commitment's on-demand equivalent value
          commitment_on_demand_value,
          -- Usage cost at on-demand price
          ROUND(usage_cost_on_demand, 2) AS usage_cost_on_demand,
          -- CUD credits (discount amount)
          ROUND(cud_credits_discount, 2) AS cud_credits_used,
          -- âœ… CORRECT UTILIZATION = usage_cost_on_demand / commitment_on_demand_value * 100
          -- This compares apples to apples (both at on-demand price level)
          ROUND(SAFE_DIVIDE(usage_cost_on_demand, commitment_on_demand_value) * 100, 2) AS utilization_percentage,
          -- Alternative calculation using credits (should be similar)
          ROUND(SAFE_DIVIDE(cud_credits_discount, commitment_on_demand_value) * 100, 2) AS utilization_by_credits,
          -- Unused portion (at on-demand value)
          ROUND(commitment_on_demand_value - usage_cost_on_demand, 2) AS unused_commitment,
          -- Estimated monthly cost
          ROUND(commitment_cost_discounted * (30.0 / days_active), 2) AS estimated_monthly_cost,
          currency,
          first_seen,
          last_seen,
          days_active,
          -- Determine status
          CASE
            WHEN days_active >= {days_lookback} - 5 THEN 'ACTIVE'
            WHEN days_active < 5 THEN 'POTENTIALLY_EXPIRED'
            ELSE 'PARTIAL'
          END AS status
        FROM combined_data
        ORDER BY estimated_monthly_cost DESC, project_id, region
        """

        logger.debug("æ‰§è¡Œä¿®æ­£åçš„ BigQuery æŸ¥è¯¢...")
        query_job = bq_client.query(query)
        results = query_job.result()

        # Process results
        commitments = []
        total_monthly_cost = 0.0
        total_commitment_cost = 0.0
        total_cud_used = 0.0
        total_utilization_sum = 0.0
        commitment_count = 0
        project_set = set()
        region_set = set()
        resource_type_counts = {}
        currency = "USD"

        # ğŸ› FIX: å»é‡ - æ¯ä¸ª project+region çš„ CUD ä½¿ç”¨é‡åªè®¡ç®—ä¸€æ¬¡
        seen_project_regions = set()

        for row in results:
            commitment = {
                "project_id": row.project_id,
                "project_name": row.project_name or row.project_id,
                "region": row.region or "global",
                "sku_description": row.sku_description,
                "resource_type": row.resource_type,
                "commitment_term": row.commitment_term,
                "commitment_cost": float(row.commitment_cost or 0),
                "cud_credits_used": float(row.cud_credits_used or 0),
                "utilization_percentage": float(row.utilization_percentage or 0),
                "unused_commitment": float(row.unused_commitment or 0),
                "estimated_monthly_cost": float(row.estimated_monthly_cost or 0),
                "currency": row.currency,
                "first_seen": str(row.first_seen),
                "last_seen": str(row.last_seen),
                "days_active": int(row.days_active),
                "status": row.status,
            }

            commitments.append(commitment)
            total_monthly_cost += commitment["estimated_monthly_cost"]
            total_commitment_cost += commitment["commitment_cost"]

            # ğŸ› FIX: CUD ä½¿ç”¨é‡å»é‡ï¼ˆæ¯ä¸ª project+region åªåŠ ä¸€æ¬¡ï¼‰
            # åŸå› ï¼šSQL JOIN å¯¼è‡´åŒä¸€ä¸ª project+region çš„ cud_credits_used åœ¨å¤šä¸ª SKU è¡Œä¸­é‡å¤
            project_region_key = (row.project_id, row.region or "global")
            if project_region_key not in seen_project_regions:
                seen_project_regions.add(project_region_key)
                total_cud_used += commitment["cud_credits_used"]

            total_utilization_sum += commitment["utilization_percentage"]
            commitment_count += 1
            project_set.add(row.project_id)
            region_set.add(row.region or "global")

            # Count by resource type
            resource_type = row.resource_type
            resource_type_counts[resource_type] = resource_type_counts.get(resource_type, 0) + 1

            currency = row.currency

        # Calculate overall metrics
        avg_utilization = (total_utilization_sum / commitment_count) if commitment_count > 0 else 0
        overall_utilization = (
            (total_cud_used / total_commitment_cost * 100) if total_commitment_cost > 0 else 0
        )

        # Build summary
        summary = {
            "total_count": len(commitments),
            "total_commitment_cost": round(total_commitment_cost, 2),
            "total_cud_credits_used": round(total_cud_used, 2),
            "total_unused_commitment": round(total_commitment_cost - total_cud_used, 2),
            "total_estimated_monthly_cost": round(total_monthly_cost, 2),
            "average_utilization_percentage": round(avg_utilization, 2),
            "overall_utilization_percentage": round(overall_utilization, 2),
            "unique_projects": len(project_set),
            "unique_regions": len(region_set),
            "resource_type_breakdown": resource_type_counts,
            "currency": currency,
            "analysis_period": f"{start_date_str} to {end_date_str}",
            "data_source": "BigQuery Billing Export",
            "method": "SKU Pattern Matching (Commitment v1:)",
            "note": f"åˆ†æäº†è¿‡å» {days_lookback} å¤©çš„è´¦å•æ•°æ®ï¼ˆæ’é™¤æœ€è¿‘2å¤©ï¼‰",
        }

        logger.info(
            f"âœ… {operation} å®Œæˆ - "
            f"æ‰¾åˆ° {len(commitments)} ä¸ªæ‰¿è¯º, "
            f"æ€»æœˆåº¦æˆæœ¬: ${total_monthly_cost:.2f}, "
            f"æ•´ä½“åˆ©ç”¨ç‡: {overall_utilization:.1f}%"
        )

        return {
            "success": True,
            "data": {"commitments": commitments, "summary": summary},
            "message": f"ä» BigQuery æå–äº† {len(commitments)} ä¸ª CUD æ‰¿è¯º",
        }

    except Exception as e:
        error_msg = f"{operation} failed: {str(e)}"
        logger.error(f"âŒ {error_msg}", exc_info=True)
        import traceback

        logger.error(f"Stack trace:\n{traceback.format_exc()}")
        return {"success": False, "error_message": error_msg, "data": None}
